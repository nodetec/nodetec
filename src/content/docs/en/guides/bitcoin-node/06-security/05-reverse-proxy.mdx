---
label: Reverse Proxy
slug: en/guides/bitcoin-node/security/reverse-proxy
order: 50
---

import Callout from "@components/mdx/Callout.tsx";

# Reverse Proxy

As we progress through this guide we'll be installing software that exposes communication ports, e.g., the Electrum server and the blockchain explorer. The communication of the software we install should always be encrypted even if we only use these services within our LAN. Any device within the same network has the ability to listen into the exchanged data including highly sensitive data like passwords, so this communication should always be encrypted.

To encrypt the communication we'll be using [NGINX](https://nginx.org/en/) as a **reverse proxy** that is configured to use **Secure Sockets Layer/Transport Layer Security (SSL/TLS)**. By using NGINX as a reverse proxy with SSL/TLS enabled we'll be able encrypt communication outside of the node and route the traffic back to the internal services of the node with the data decrypted.

Before setting up NGINX as a reverse proxy using SSL/TLS we're going to discuss the following topics:

- What is a reverse proxy

- How to create an SSL/TLS certificate

- The basics of NGINX

## What is a Reverse Proxy

A **proxy server** is a server that sits between a client and the internet that provides indirect network services to the client. It can be on the user's local device or at various points between the user's device and the server we want to access on the internet which we'll refer to as the **origin server**.

A proxy server is used to intercept all client requests and provides responses from its cache or forwards the requests to the origin server. The client requests may include files or any other resource available on the origin server.

There are multiple types of proxy servers based on their purpose and functionality. Here we're going to focus on the reverse proxy server.

A reverse proxy is positioned in front of the origin server and handles processing and forwarding requests from clients. It provides an additional layer of security and performance improvements to optimize a service.

A reverse proxy works by intercepting a request from a client, performing some action on the request, then sending the request to the origin server in the network. The origin serverâ€™s response then travels back through the reverse proxy which gives the impression to clients that the proxy server handled the request on its own.

## SSL/TLS

SSL and TLS are both cryptographic protocols designed to provide communication security over a computer network by encrypting data and authenticating connections. TLS is the more recent version of SSL which fixes some security vulnerabilities in the earlier SSL versions.

The SSL/TLS certificate can be shared publicly, e.g., you can share it with the client you're using to access your node with. Public key cryptography is used when creating the certificate. The certificate contains the public key and the private key remains on the server and should be properly secured there. The public key and the corresponding private key are referred to as a key pair.

The certificate is used to perform a "handshake" between the server and the client using **asymmetric encryption**. During the handshake the public key is used for encryption and the private key is used for decryption. The asymmetric encryption uses the key pair to authenticate the identity of the server and to exchange data between them, e.g., the version of SSL/TLS being used, the **cipher suite** being used to encrypt the communication, establishing that a secure connection is in place before the data transfer begins, etc.

This exchange of data is used to generate **session keys**. The sessions keys are generated by using a key exchange algorithm, e.g. Diffie-Hellman (DH) using the key pair that was generated when creating the certificate. The session keys are then used to perform **symmetric encryption** of the communication session once the handshake is complete. The server and the client can agree upon new session keys for each communication session. This means even if an attacker identifies or steals one of the session keys from a previous session they'll be unable to decrypt the new communication session.

<Callout client:load type="tip">
  Usually, the handshake performed between the server and the client is used to authenticate the identity of the server. It is possible though to set up a handshake that also requires the client to send a certificate containing a public key to the server which is used to authenticate the identity of the client. This **two-way authentication** adds more overhead to the handshake, but it adds another layer of security since only authenticated clients will be able to establish a communication session with the server.
</Callout>

### Self-signed Certificate

A **self-signed SSL/TLS certificate** encrypts communication between the server and clients; however, the certificate isn't signed by any trusted **Certificate Authority (CA)**. A CA is a trusted third-party organization that verifies the authenticity of a server usually for a website to ensure the users are communicating with an official server and not a fake one set up to steal data.

The verification process involves generating a **Certificate Signing Request (CSR)** which is an encrypted block of text that includes various information about your server including the country code, state/region/province, locality name, organization name, organizational unit name, common name, e.g., the FQDN of the server, the email address, etc. The CSR and public key are then sent to the CA which will verify the identity and whether or not you control the domain submitted in the application.

Since we don't want to send Personal Identifiable Information (PII) about our node to a CA, and we're not planning on using a domain name with our node accessible on the **clearnet**, we're going to use a self-signed certificate. However, by using a self-signed certificate users cannot validate the identity of the server automatically.

### Creating the Certificate

To create a self-signed SSL/TLS certificate we'll be using [OpenSSL](https://www.openssl.org/) which contains a FOSS implementation of the SSL and TLS protocols as well as other cryptography standards and tools.

OpenSSL should already be installed on your node, but if it isn't here's how to install it

```sh:Install OpenSSL
sudo apt install -y openssl
```

After installing OpenSSL, we can create a self-signed SSL/TLS certificate by running the following command:

```sh:Create a Self-signed SSL/TLS Certificate
sudo openssl req -x509 -sha256 -days 3650 -newkey rsa:4096 -noenc -keyout /etc/ssl/private/nginx-self-signed.key -out /etc/ssl/certs/nginx-self-signed.crt -subj "/CN=localhost"
```

Here's what each part of the command does:

- `openssl`: This is the OpenSSL command line tool which allows you to use the various cryptography functions of OpenSSL's crypto library.

- `req`: This command primarily creates and processes CSRs in **Public Key Cryptography Standards (PKCS) #10** format. It can also be used to create and process self-signed certificates.

- `-x509`: This option signifies we want to create a new self-signed certificate instead of a CSR using the **X.509** standard as the format for the public key certificate.

- `-sha256`: This option specifies that we want to use the **SHA-256** hash function when generating the certificate.

- `-days`: This option specifies the number of days the certificate is valid for. The value should be a positive integer, and the default value is `30` days. For a self-signed certificate this value can be increased as necessary. We'll be using a value of `3650` days which is approximately 10 years.

- `-newkey`: This option specifies that we want to generate a new key to use with the certificate we're creating. The default value uses `rsa:2048`, i.e., an RSA key that has a key size of `2048` bits. We'll be using `rsa:4096`, i.e., an RSA key that has a key size of `4096`.

- `-noenc`: This option informs OpenSSL that we don't want to encrypt the private key that we'll be generating with the certificate. If this option is excluded, then you'll be required to enter the passphrase used to encrypt the private key each time the application using it restarts. We want NGINX to be able to read the file every time it restarts without our intervention which is why we're specifying this option. If you're not using OpenSSL 3.0 or a newer version, then you need to use the `-nodes` option instead.

- `-out`: This options specifies where we want to place the self-signed certificate we're creating. We'll be using the OpenSSL certicates location, i.e., `/etc/ssl/certs`, and we'll be using `nginx-self-signed.crt` for the file name of the certificate.

- `-keyout`: This option specifies where we want to place the private we generated with the self-signed certificate. We'll be using the OpenSSL private keys location, i.e., `/etc/ssl/private`, and we'll be using `nginx-self-signed.key` for the file name of the priate key.

- `-subj`: This option sets the subject of the certificate. When an argument is provided to this option it lets us non-interactively answer the certificate information prompt, i.e., it lets us set the values for the country code, state/region/province, locality name, organization name, organizational unit name, common name, the email address, etc. Any fields that are not specified in the `-subj` option will be left blank. Since we're creating a self-signed certificate that will be used on our LAN, we're going to set the common name, i.e., `CN` to be `localhost` using `-subj "/CN=localhost"`, and we can leave the other fields empty.

<Callout client:load type="warning">
  You can specify values for the others fields in the certificate information prompt by not specifying the `-subj` option and setting them interactively or by specifiying them in the `-subj` option. However, if you set these fields with PII and share the certificate with your client(s), then this information can be leaked. That is why we're only setting the `CN` field with a value of `localhost`.
</Callout>

### Verification

After creating the self-signed certificate and the private key, we can confirm the integrity of the key pair by taking the following steps:

1. First, we can verify the integrity of the private key to ensure it hasn't been tampered with.

2. Next, we can verify that the `modulus` of both the private and public key match.

3. Then, we can test the encryption with the public key from the certificate and the decryption with the private key.

4. Finally, we can confirm the integrity of a file which is signed with the private key.

#### Private Key Integrity

To verify the integrity of the private key we can run the following command:

```sh:Private Key Integrity
sudo openssl rsa -in /etc/ssl/private/nginx-self-signed.key -check -noout
```

If the private key is valid the output of the command should look similar to:

```sh:Valid Private Key Integrity Output
RSA key ok
```

If you see the output above, then the private key is valid,

<Callout client:load type="error">
  If you see output that looks similar to `RSA key error...`, then the private key failed the integrity check. This means your private key has been tampered with, and you should create a new certificate and private key.
</Callout>

#### Public and Private Key Modulus

To verify that the `modulus` of the public and private key match we can compare the **md5 checksums** of the certificate and the private key.

To get the md5 checksum for the public key you can run the following command:

```sh:Public Key md5 Checksum
openssl x509 -noout -modulus -in /etc/ssl/certs/nginx-self-signed.crt | openssl md5
```

The output should look similar to:

```sh:Public Key md5 Checksum Output
MD5(stdin)= 2147b185d577a98d8ab6fa303497d08c
```

To get the md5 checksum for the private key you can run the following command:

```sh:Private Key md5 Checksum
sudo openssl rsa -noout -modulus -in /etc/ssl/private/nginx-self-signed.key | openssl md5
```

The output should look similar to:

```sh:Private Key md5 Checksum Output
MD5(stdin)= 2147b185d577a98d8ab6fa303497d08c
```

If the md5 checksums of the public and private keys match *exactly*, then the `modulus` matches.

<Callout client:load type="error">
  If the md5 checksums don't match *exactly*, then you should recreate the certificate and the private key.
</Callout>

#### Encryption and Decryption

To perform encryption with the public key we can extract the public key from the certificate and output it to a file by running the following command:

```sh:Output Public Key to a File
openssl x509 -in /etc/ssl/certs/nginx-self-signed.crt -noout -pubkey > $HOME/nginx-self-signed.pub.crt
```

After running the above command the public key from the certificate will be output to the file `nginx-self-signed.pub.crt` in the `/home/<username>` directory where `<username>` is the username you set during the installation.

To view the public key you can run the following command:

```sh:View Public Key
cat $HOME/nginx-self-signed.pub.crt
```

The public key will look something like this:

```sh:Public Key
-----BEGIN PUBLIC KEY-----
MIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAnkv50W6F0M5DyhQPrSq6
12dZk1xStiCOJY5vS+VuWyXhvg/B+z/LWcjL8uBEOmLjjMi67Vi8KzSIDOX/oJYo
feB5/AtlmwK2kGJxMgixMYMp0dRwjY1NAYgXYHHCFnxLDhen2PkxHeYecEnuABIC
6DrZeuKswj0Ua9oSBH7arp2R+R+ycEPe99w0Hi33jffeBPxputp9LW6ICXewecn4
Q1RxTIgEYh3PWEitJaS2TYDo9ErWfHDInbJaOc1z2XV9lqmMipk6XvkoJA0uA6K/
0U/tGOUavKJNzAKyr2euBZmGWgjwRfWY+GWdYWFnquNA90R+qvHAz3RcqfHHipVv
KI3oGKq29UEm0sKlgr67TT+Go1KZ6P1Cck1VoTtWHFwOjQlunkbjUHcmlvN5o+vp
aKvWQrsZYIHtWyuunOvFL34afVefu+9ufFm5wmPf+FUuPpimUEDxTtNVnTilydYU
JvfOHaRWw8vhqxmzVJ67W1BxMd57fcEOs3LCVSgpNJ5bB+cZGymxDq2vuy807KjK
sP+eKcMbnZscg/apLE9aRr/K4/BEKu05xhtnCef31O5g8eT/tK2oH5EOoWP6MUGM
IxFLFTrD9KPSh2fkyI3IZe65MWieLFADoEch7RLAwBJvXq/0Es5aiTAvYH454see
7gAsWMJNBP9ITAJrO3jmHM0CAwEAAQ==
-----END PUBLIC KEY-----
```

Now that we have the public key saved to a file, we can create a test file, e.g., `test.txt` and add content to the file, e.g., `test` by running the following command:

```sh:Create test.txt File
echo "test" > $HOME/test.txt
```

After creating the test file, we can create an encrypted message by running the following command:

```sh:Create Encrypted Message
openssl pkeyutl -encrypt -in $HOME/test.txt -pubin -inkey $HOME/nginx-self-signed.pub.crt -out $HOME/cipher.txt
```

After running the above command the encrypted message will be output to the file `cipher.txt` in the `/home/<username>` directory where `<username>` is the username you set during the installation.

To decrypt the message in `cipher.txt` we can run the following command:

```sh:Decrypt Message
sudo openssl pkeyutl -decrypt -in $HOME/cipher.txt -inkey /etc/ssl/private/nginx-self-signed.key
```

If the decryption is successful, then the output of the command will be the content of the `test.txt` file:

```sh:Successful Decryption Output
test
```

<Callout client:load type="error">
  If the decrypted message doesn't match the content in the test file, then you should create a new certificate and private key since the private key has been tampered with.
</Callout>

#### Private Key Signature

To confirm the integrity of a file which is signed with the private key we can sign the `test.txt` file we previously created by running the following command:

```sh:Sign test.txt File
sudo openssl dgst -sha256 -sign /etc/ssl/private/nginx-self-signed.key -out $HOME/test.txt.sig $HOME/test.txt
```

After running the above command, the signature for the `test.txt` file will be output to the file `test.sig` in the `/home/<username>` directory where `<username>` is the username you set during the installation.

We can now verify the signed file with the public key that we previously extracted to the `nginx-self-signed.pub.crt` file by running the following command:

```sh:Verify Signature
sudo openssl dgst -sha256 -verify $HOME/nginx-self-signed.pub.crt -signature $HOME/test.txt.sig $HOME/test.txt
```

If the verification is successful, then the output of the command will look something like:

```sh:Successful Signature Verification Output
Verified OK
```

<Callout client:load type="error">
  If the signature verification isn't successful, then the output will look something like this `Verification Failure`. This means the private key has been tampered with, so you should create a new certificate and private key.
</Callout>

#### Deleting Files

After performing the verification steps above, we no longer need the files we created during the verification process.

To delete these files we can run the following command:

```sh:Delete Verification Files
rm -rf nginx-self-signed.pub.crt test.txt cipher.txt test.txt.sig
```

## NGINX

NGINX is FOSS used for web serving, reverse proxying, caching, media streaming, and more. As mentioned above we'll be using it as a reverse proxy that is configured to use SSL/TLS using the self-signed certificate we just created.

### Installation

NGINX gives us the option of choosing between the following versions:

- **Mainline**: This version includes all of the latest features and bug fixes, and it's always up to date. Even though this version tends to be reliable, it also contains some experimental modules as well as the possibility of introducing new bugs.

- **Stable**: This version doesn't include all of the latest features, but it does contain all of the known critical bug fixes. It's recommended to use this version with all production servers.

Since we'll be using our node in a production environment, we'll be using the stable version.

<Callout client:load type="info">
  NGINX modules basically add more functionality to NGINX. There are core modules supported by NGINX as well as third-party modules which are created and maintained by members of the NGINX community. It's possible to gain more control over which modules you install depending on your chosen NGINX installation method.
</Callout>

Here are the NGINX installation methods:

- **Prebuilt Debian package from OS Respository**: This is the quickest method but the package may be outdated and less flexible since it includes almost all of the NGINX modules.

- **Prebuilt Debian Package from NGINX Repository**: This method requires a little more work since you have to initially set up the `apt` repository, but the package will always be the latest version when updating. The install also includes almost all of the NGINX modules as well.

- **Compile from Source**: This method requires the most work, but it gives you the most flexibility since you can customize which modules you install from NGINX and other third parties. It also gives you the ability to apply the latest security patches.

We'll be going over how to install NGINX using the first two options listed above.

<Callout client:load type="tip">
  If the installation methods described here are not working, then you can refer to [Installing NGINX Open Source](https://docs.nginx.com/nginx/admin-guide/installing-nginx/installing-nginx-open-source/).
</Callout>

#### Prebuilt Debian Package from OS Repository

Before installing NGINX, we're going to fetch the information about the latest versions of the packages available for our system by running the following command:

```sh:Update apt
sudo apt update
```

After running the above command, we're now able to install the latest version of NGINX from the OS repository.

To install NGINX from the OS respository run the following command:

```sh:Install using OS Repository
sudo apt install -y nginx
```

#### Prebuilt Debian Package from NGINX Repository

Before installing the prebuilt Debian package from the NGINX repository, we need to first install the following dependencies which may already be installed on your system:

```sh:Install Dependencies
sudo apt install -y curl gnupg2 ca-certificates lsb-release debian-archive-keyring
```

Next, we need to import an official NGINX signing key which allows `apt` to verify the authenticity of the package which we can do by running the following command:

```sh:Import NGINX Signing Key
curl https://nginx.org/keys/nginx_signing.key | gpg --dearmor \
    | sudo tee /usr/share/keyrings/nginx-archive-keyring.gpg >/dev/null
```

Now we need to verify the file we downloaded contains the proper key which we can do by running the following command:

```sh:Verify NGINX Signing Key
gpg --dry-run --quiet --no-keyring --import --import-options import-show /usr/share/keyrings/nginx-archive-keyring.gpg
```

The output should look like this:

```sh:Verification Output
pub   rsa2048 2011-08-19 [SC] [expires: 2024-06-14]
      573BFD6B3D8FBC641079A6ABABF5BD827BD9BF62
uid                      nginx signing key <signing-key@nginx.com>
```

If the output doesn't contain the following fingerprint `573B FD6B 3D8F BC64 1079 A6AB ABF5 BD82 7BD9 BF62`, then you should remove the imported signing key.

<Callout client:load type="tip">
  The NGINX signing key may be changed in the future, so you can refer to the [nginx: Linux packages](https://nginx.org/en/linux_packages.html#Debian) page to see if the key has been changed. The page also goes over the installation process as well.
</Callout>

We're now going to set up `apt` to use the stable version by running the following command:

```sh:Set Up apt to Use Stable Version
echo "deb [signed-by=/usr/share/keyrings/nginx-archive-keyring.gpg] \
http://nginx.org/packages/debian `lsb_release -cs` nginx" \
    | sudo tee /etc/apt/sources.list.d/nginx.list
```

We now need to set up the repository pinning to prefer the package from the NGINX repository instead of the OS repository by running the following command:

```sh:Set Up Repository Pinning
echo -e "Package: *\nPin: origin nginx.org\nPin: release o=nginx\nPin-Priority: 900\n" \
    | sudo tee /etc/apt/preferences.d/99nginx
```

After setting up the respository pinning, we're going to fetch the information about the latest versions of the packages available for our system by running the following command:

```sh:Update apt
sudo apt update
```

After running the above command, we're now able to install the latest version of NGINX from the NGINX repository.

To install the latest NGINX package from the NGINX respository run the following command:

```sh:Install using NGINX Repository
sudo apt install -y nginx
```

### Check Version

After installing NGINX, you can check the version by running the following command:

```sh:Check Version
sudo nginx -v
```

The output should look similar to:

```sh:Version Output
nginx version: nginx/1.24.0
```

### Check NGINX Status

To check the `status` of NGINX run the following command:

```sh:Check NGINX Status
sudo systemctl status nginx
```

The output should look similar to:

```sh:NGINX Status Output
â—‹ nginx.service - nginx - high performance web server
     Loaded: loaded (/lib/systemd/system/nginx.service; enabled; preset: enabled)
     Active: inactive (dead)
       Docs: https://nginx.org/en/docs/
```

From the output of the command weâ€™re able to determine the following about NGINX:

- If it's running

- If it's set to automatically start on boot

#### Check if NGINX is Running

If we look at the following line:

```sh:Check if NGINX is Running
Active: inactive (dead)
```

Then we see that NGINX isn't currently running since the status shows `inactive (dead)`.

If you see `active (running)`, then NGINX is running.

#### Check if NGINX is Enabled

If we look at the following line:

```sh:Check if NGINX is Enabled
Loaded: loaded (/lib/systemd/system/nginx.service; enabled; preset: enabled)
```

Then we see that NGINX is set to automatically start on boot since the service is `enabled`.

If you see `disabled`, then NGINX isn't set to automatically start on boot.

### Enable NGINX

If NGINX isn't enabled to automatically start on boot, then run the following command:

```sh:Enable NGINX
sudo systemctl enable nginx
```

### Disable NGINX

If you want to disable NGINX from automatically starting on boot, then run the following command:

```sh:Disable NGINX
sudo systemctl disable nginx
```

### Start NGINX

If NGINX isnâ€™t running, then run the following command to start the service:

```sh:Start NGINX
sudo systemctl start nginx
```

<Callout client:load type="tip">
  If you're getting an error when starting NGINX, try rebooting the system using `sudo systemctl reboot`.
</Callout>

### Stop NGINX

If you want to stop NGINX, then run the following command:

```sh:Stop NGINX
sudo systemctl stop nginx
```

### Reload NGINX

We can also load configuration updates without performing a complete reboot of NGINX by running the following command:

```sh:Reload NGINX
sudo systemctl reload nginx
```

### Restart NGINX

If you want to restart NGINX which completely stops then starts the service, then you can run the following command:

```sh:Restart NGINX
sudo systemctl restart nginx
```

### Configuration Files

By default NGINX is configured to handle HTTP traffic. Since we're not using HTTP we're going to update the configuration to handle TCP and UDP traffic directly with SSL/TLS enabled.

To update the configuration we need to update the `nginx.conf` file which can be found in the `/etc/nginx` directory.

Here's how to open the `nginx.conf` file:

```sh:Open nginx.conf File
sudo nano /etc/nginx/nginx.conf
```

The content of the file should look similar to:

```sh:nginx.conf File

user  nginx;
worker_processes  auto;

error_log  /var/log/nginx/error.log notice;
pid        /var/run/nginx.pid;


events {
    worker_connections  1024;
}


http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    keepalive_timeout  65;

    #gzip  on;

    include /etc/nginx/conf.d/*.conf;
}
```

#### Directives

The configuration file consists of **directives** and their paramters. There are single-line directives, e.g., `user  nginx;` that each end with a semicolon as well as directives that act as **containers** which group togther related directives by enclosing them in curly braces, i.e., `{}`. These containers are commonly referred to as **blocks**.

Here's an example of of a container from the configuration file:

```sh:Container Example
events {
    worker_connections  1024;
}
```

#### Contexts

There are also a few top-level containers that are used to group together directives that apply to different traffic types which are referred to as **contexts**.

Here are some common contexts:

- `events`: General connection processing

- `http`: HTTP traffic

- `mail`: Mail traffic

- `stream`: TCP and UDP traffic

From the configuration file we can see there is an `http` context which is used to handle HTTP traffic:

```sh:Context Example
http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    keepalive_timeout  65;

    #gzip  on;

    include /etc/nginx/conf.d/*.conf;
}
```

Directives that are placed outside of these contexts are said to be in the **main** context.

#### Feature-Specific Configuration Files

To make the configuration updates easier to maintain, it's recommended to split the configuration updates into **feature-specific** files placed in the `/etc/nginx/conf.d` directory. These feature-specific files can then be referenced in the `nginx.conf` file using the `include` directive.

If we take a look at the configuration file we see the following `include` directives:

```sh:Include Directives
include       /etc/nginx/mime.types;
...
include /etc/nginx/conf.d/*.conf;
```

The first include directive is being used to reference **Multipurpose Internet Mail Extensions (MIME) types**. MIME types are a way of identifying files based on their format and content. MIME types were originally created for emails. Today this standard is used for identifying the format and content for many more protocols and is now referred to as **Internet Media Types** or **Content-types**.

The second include directive is being used to reference all of the files located in the `/etc/nginx/conf.d` directory that end with the `.conf` file extension. The ability to reference all of the files ending with a `.conf` file extension is accomplished by using the `*` wildcard.

To view the content located in the `conf.d` directory, we can run the following command:

```sh:List Content of conf.d
ls /etc/nginx/conf.d
```

The output should look similar to:

```sh:List Output
default.conf
```

From the output we can see there is a default configuration file located in the `conf.d` directory named `default.conf`.

We can open the file using the following command:

```sh:Open default.conf File
sudo nano /etc/nginx/conf.d/default.conf
```

The content of the file should look similar to:

```sh:default.conf File
server {
    listen       80;
    server_name  localhost;

    #access_log  /var/log/nginx/host.access.log  main;

    location / {
        root   /usr/share/nginx/html;
        index  index.html index.htm;
    }

    #error_page  404              /404.html;

    # redirect server error pages to the static page /50x.html
    #
    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
        root   /usr/share/nginx/html;
    }

    # proxy the PHP scripts to Apache listening on 127.0.0.1:80
    #
    #location ~ \.php$ {
    #    proxy_pass   http://127.0.0.1;
    #}

    # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
    #
    #location ~ \.php$ {
    #    root           html;
    #    fastcgi_pass   127.0.0.1:9000;
    #    fastcgi_index  index.php;
    #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
    #    include        fastcgi_params;
    #}

    # deny access to .htaccess files, if Apache's document root
    # concurs with nginx's one
    #
    #location ~ /\.ht {
    #    deny  all;
    #}
}
```

Here the `default.conf` file is using a `server` block which is used to define a **virtual server**.

#### Virtual Servers

Virtual servers are used to control the processing of requests, and the directives included within a `server` block vary depending on the traffic type.

The `server` block being used in the `default.conf` file is being used in the `http` context, so each directive in the `server` block controls the processing of requests for resources at specified domains or IP addresses. To specify how to process requests at specific **Uniform Resource Identifiers (URIs)**, the `location` block is used, e.g., the configuration for processing URIs starting with `/` is specified by `location /`.

For mail and TCP/UDP traffic, i.e., the `mail` and `stream` contexts the `server` directives control the processing of traffic arriving at a particular TCP port or UNIX socket.

### Configuration Backup

Before configuring NGINX as a reverse proxy with SSL/TLS enabled, we're going to first backup the default `nginx.conf` file. By backing up the configuration file we'll have a reference to the original file. Having a reference to the original file can be useful, e.g., if an error occurs it can help us determine if a changed we made is responsible for the error.

To backup the `nginx.conf` file we can run the following command:

```sh:Backup nginx.conf File
sudo mv /etc/nginx/nginx.conf /etc/nginx/nginx.conf.bak
```

The command above renames the `nginx.conf` file to `nginx.conf.bak` and places it in the same directory, i.e., `/etc/nginx`.

### NGINX as a Reverse Proxy with SSL/TLS

Now that we've gone over the basics of NGINX and created a backup of the configuration file, we're ready to configure NGINX as a reverse proxy with SSL/TLS enabled using the SSL/TLS self-signed certificate and the corresponding private key we created.

#### Create self-signed.conf File

We're going to start by creating a directory named `stream` in the `/etc/nginx/conf.d` directory which we're going to use to organize the configuration files related to the SSL/TLS settings.

To create the `stream` directory we need to run the following command:

```sh:Create stream Directory
sudo mkdir /etc/nginx/conf.d/stream
```

We're now going to create a file named `self-signed.conf` which will contain information about the locations of the SSL/TLS self-signed certificate and the corresponding private key in the `stream` directory.

To create and open the file we can run the following command:

```sh:Create and Open self-signed.conf
sudo nano /etc/nginx/conf.d/stream/self-signed.conf
```

We're now going to set the `ssl_certificate` directive to the path of the SSL/TLS self-signed certificate we created, and we're going to set the `ssl_certificate_key` directive to the path of the corresponding private key by adding the following lines to the `self-signed.conf` file:

```sh:self-signed.conf
ssl_certificate /etc/ssl/certs/nginx-self-signed.crt;
ssl_certificate_key /etc/ssl/private/nginx-self-signed.key;
```

We can now save the file and exit.

#### Diffie-Hellman Parameters

Next we're going to generate stronger **Diffie-Hellman Ephemeral (DHE)** parameters which are used when implementing **Forward Secrecy (FS)** also known as **Perfect Forward Secrecy (PFS)**.

FS is a feature of specific key-agreement protocols that give assurances that session keys won't be compromised even if long-term secrets used in the session key exchange are compromised this. FS protects the communication of past sessions against future compromises of long-term secrets. Here the long-term secret is the private key we generated on the server.

To generate stronger DHE parameters we can run the following command:

```sh:Generate Stronger DHE Parameters
sudo openssl dhparam -out /etc/nginx/conf.d/stream/dhparam.pem 4096
```

<Callout client:load type="info">
  The generation of stronger DHE parameters may take a while, so be patient and don't interrupt the process.
</Callout>

#### Create ssl-params.conf File

We're now going to create a file named `ssl-params.conf` in the `/etc/nginx/conf.d/stream` directory which will be used to set strong encryption settings and to enable some advanced features that will help keep the node secure.

To create and open the file we can run the following command:

```sh:Create and Open ssl-params.conf File
sudo nano /etc/nginx/conf.d/stream/ssl-params.conf
```

We're now ready to set the directives for strong encryption and advanced features. These directives are adapted from the [Mozilla SSL Configuration Generator](https://ssl-config.mozilla.org/#server=nginx&version=1.17.7&config=intermediate&openssl=1.1.1k&guideline=5.7) which is a useful resource that provides recommendations for how to securely configure popular server software for modern, intermediate, and old clients.

```sh:ssl-params.conf
ssl_session_timeout 5m;
ssl_session_cache shared:SSL:1m;
ssl_session_tickets off;

ssl_protocols TLSv1.2 TLSv1.3;
ssl_prefer_server_ciphers on;
ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-CHACHA20-POLY1305;

ssl_dhparam /etc/nginx/conf.d/stream/dhparam.pem;
ssl_ecdh_curve X25519:secp521r1:secp384r1:prime256v1;
```

We can now save the file and exit.

Here's a description of what each directive does:

- `ssl_session_timeout`: Sets the time during which a client may reuse the session parameters. Here we set the directive to be `5m`, i.e., 5 minutes which is the default value.

- `ssl_session_cache`: Sets the types and sizes of caches that store session parameters. Here we're using a cache with a type of `shared` which specifies we want to share the cache between all worker processes. The cache size is specified in bytes where 1MB can store about 4000 sessions. Here we're setting a cache size of `1m`, i.e., 1MB. Each shared cache can have an arbitrary name, and a cache with the same name can be used in several virtual servers. Here we're setting the cache name to be `SSL`. This directive also automatically generates, stores, and periodically rotates the SSL/TLS session ticket keys unless they're explicitly configured using the `ssl_session_ticket_key` directive.

- `ssl_session_tickets`: Enables or disables session resumption through TLS session tickets. Here we set the value to `off` to prevent possible forward secrecy issues due to improper rotation of the session ticket encryption key.

- `ssl_protocols`: Sets the SSL/TLS protocol version the server should use. All protocols other than `TLSv1.2` and `TLSv1.3` are considered insecure.

- `ssl_prefer_server_ciphers`: When choosing a cipher to use when encrypting the communication usually the client's preference is used. By setting this directive to `on`, we're ensuring the server's preference is used which prevents a client from using a less secure cipher. If you prefer you can set this directive to `off` which will allow the client to choose the most performant cipher suite for their hardware configuration. All of the ciphers used in `TLSv1.3` and `TLSv1.2` are currently considered secure as well if you prefer to use a more performat cipher suite.

- `ssl_ciphers`: Specifies the enabled ciphers to use where the order determines which algorithms are going to be selected first. This directive sets the ciphers to use with `TLSv1.2`. The ciphers for `TLSv1.3` are automatically enabled, so they don't have to be set.

- `ssl_dhparam`: Sets the path to the file containing the DH parameters we want to use with the DHE ciphers. By default no parameters are set, so DHE ciphers will not be used in the configuration.

- `ssl_ecdh_curve`: Specifies a curve to use with ECDHE ciphers. Here the curves are ordered with the strongest curve first. The default value is `auto` which instructs NGINX to use a list built into the OpenSSL library. This directive also sets the list of curves supported by the server. This means if you're using an ECDSA certificate, then you need to also include the curves used in the certificate.

<Callout client:load type="tip">
  The recommended settings from the Mozilla SSL Configuration Generator provide strong security at the cost of wider client compatibility. If you're experiencing issues, e.g., you need to support an older client, then you can use the older configuration. However, it's recommended to use the newer configurations.
</Callout>

#### Create nginx.conf File

We're now going to create the `nginx.conf` file in the `/etc/nginx` directory. We'll use this file to configure settings that affect the entire NGINX application as well as to import the SSL/TLS settings we just configured.

The directives we place here outside of curly braces, i.e., `{}` will be in the main context which means these settings will affect the entire NGINX application. Many of the directives set in the main context cannot be overridden in lower contexts since they're used to set global NGINX settings.

Some common settings that are configured in the main context include the system user and group used to run the worker processes, the number of worker processes, the file used to save the main NGINX PID, the default error file for logging, etc.

To create and open the file we can run the following command:

```sh:Create and Open nginx.conf File
sudo nano /etc/nginx/nginx.conf
```

Here's what the `nginx.conf` file looks like after setting the configuration:

```sh:nginx.conf
user nginx;
worker_processes auto;

error_log /var/log/nginx/error.log notice;
pid /var/run/nginx.pid;

events {
  worker_connections 1024;
}

stream {
  include /etc/nginx/conf.d/stream/*.conf;
}
```

We can now save the file and exit.

Here's a description of what each directive does:

- `user`: Defines a user and group used by the worker processes. If you don't use a group, then a group whose name equals that of user is used. Here we're using the value of `nginx` which is the default user used with the worker processes.

- `worker_processes`: Responsible for setting the number of worker processes to spawn. The optimal value depends on numerous factors including the number of CPU cores, the number of HDDs/SSDs used to store data, the load pattern, etc. A good rule of thumb is to set it to the number of available CPU cores. The default value is `1`, and here we're using `auto` which attempts to autodetect the number of available CPU cores.

- `error_log`: Sets a file to store error logs in as well as the level of logging which can be set to one of the following: `debug`, `info`, `notice`, `warn`, `error`, `crit`, `alert`, or `emerg`. The log levels here are listed in order of increasing severity. Setting a log level will cause all messages of the specified log level and more severe log levels to be logged, e.g., a log level of `crit` will cause `crit`, `alert`, and `emerg` messages to be logged. The default value is `/logs/error.log error`, and here we're using `/var/log/nginx/error.log notice`.

- `pid`: Sets a file to store the PID for the master NGINX process. The default value is `/logs/nginx.pid`, and here we're setting the value to `/var/run/nginx.pid`.

- `events`: Specifies the events context which is used to handle general connection processing.

- `worker_connections`: Sets the maximum number of simultaneous connections that can be opened by a worker process. The connections include connections with proxied servers, clients, etc. Also, the actual number of simultaneous connections cannot exceed the limit on the maximum number of open files set by the system. The default value is `512`, and here we're setting it to the value of `1024`.

- `stream`: Specifies the stream context which creates a stream proxy server that can handle TCP and UDP traffic using the SSL/TLS settings we just configured.

- `include /etc/nginx/conf.d/stream/*.conf`: Used to import the SSL/TLS settings we previously set as well as any future configuration files we create.

To apply the configuration updates we made, we can reload NGINX without performing a complete reboot by running the following command:

```sh:Reload NGINX
sudo systemctl reload nginx
```

### Test Configuration

To test the configuration updates are working, we can run the following command:

```sh:Test NGINX
sudo nginx -t
```

If the configuration is working, then the output of the command should look similar to:

```sh:NGINX Success Output
nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
nginx: configuration file /etc/nginx/nginx.conf test is successful
```

